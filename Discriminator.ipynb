{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e4fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras import Model, Input, regularizers, utils\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a8a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d3b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8309f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_img = Input(shape=(224, 224, 3))  \n",
    "    \n",
    "#Common Discrimintaor\n",
    "x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(Input_img)\n",
    "\n",
    "x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
    "\n",
    "x2 = MaxPool2D( (2, 2))(x2)\n",
    "\n",
    "x3 = Conv2D(64, (3, 3), activation='relu', padding='same')(x2)\n",
    "\n",
    "x4 = Conv2D(32, (3, 3), activation='relu', padding='same')(x3)\n",
    "\n",
    "x4 = MaxPool2D( (2, 2))(x4)\n",
    "\n",
    "x5 = Conv2D(16, (3, 3), activation='relu', padding='same')(x4)\n",
    "\n",
    "x6 = Conv2D(8, (3, 3), activation='relu', padding='same')(x5)\n",
    "\n",
    "x6 = MaxPool2D((2, 2))(x6)\n",
    "\n",
    "x7 = Conv2D(4, (3, 3), activation='relu', padding='same')(x6)\n",
    "\n",
    "x8 = Conv2D(2, (3, 3), activation=\"relu\", padding=\"same\")(x7)\n",
    "\n",
    "x8 = Flatten()(x8)\n",
    "\n",
    "x9 = Dense(256, activation=\"relu\")(x8)\n",
    "\n",
    "x10 = Dense(64, activation=\"relu\")(x9)\n",
    "\n",
    "x11 = Dense(16, activation=\"relu\")(x10)\n",
    "\n",
    "x12 = Dense(4, activation=\"relu\")(x11)\n",
    "\n",
    "x13 = Dense(1, activation=\"sigmoid\")(x12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcea5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_discriminator = Model(Input_img, x13)\n",
    "common_discriminator.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad7fff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 256)     7168      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 128)     295040    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 64)      73792     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 32)      18464     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 16)        4624      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 4)         292       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 2)         74        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1568)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               401664    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 819,839\n",
      "Trainable params: 819,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "common_discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8022ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "root = 'E:/Download/AniGAN-main/face2anime/human-faces/'\n",
    "face_images = glob.glob(root + \"*.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db56b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'E:/Download/AniGAN-main/face2anime/anime-faces/'\n",
    "anime_images = glob.glob(root + \"*.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ce38c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(face_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759145a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccea6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 78.86it/s]\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "\n",
    "for i in tqdm(face_images):\n",
    "    img = utils.load_img(i, target_size=(224,224,3))\n",
    "    img = utils.img_to_array(img)\n",
    "    all_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "810cff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 238.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(anime_images):\n",
    "    img = utils.load_img(i, target_size=(224,224,3))\n",
    "    img = utils.img_to_array(img)\n",
    "    all_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b6784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "1\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "labels = [1.0]*len(face_images) + [0.0]*len(anime_images)\n",
    "# label = 1 for human faces\n",
    "# label = 0 for anime faces\n",
    "labels = np.array(labels)\n",
    "print(len(labels))\n",
    "print(labels.ndim)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a3c70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ff256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(200, 224, 224, 3)\n",
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(all_images.ndim)\n",
    "print(all_images.shape)\n",
    "print(all_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530d4431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 0.5000\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 152s 760ms/step - loss: 0.5000\n"
     ]
    }
   ],
   "source": [
    "outcome = common_discriminator.fit(all_images, labels,\n",
    "            epochs=2,\n",
    "            batch_size=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c1b803b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 30s 4s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = common_discriminator.predict(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6b9ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above one is not so good, hence trying out another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b20d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "# model = VGG19()\n",
    "model = VGG19(weights=\"imagenet\",input_shape=(224,224,3))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "664cba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Model(model.input, model.layers[12].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7b5a06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,505,728\n",
      "Trainable params: 3,505,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53b09eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = face_images+anime_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0091fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:05<00:00, 35.63it/s]\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "\n",
    "for i in tqdm(images):\n",
    "    img = utils.load_img(i, target_size=(224,224,3))\n",
    "    img = utils.img_to_array(img)\n",
    "    \n",
    "#     print(\"Before - \", img.shape)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "#     print(\"After - \", img.shape)\n",
    "    \n",
    "    all_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3661a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(img):\n",
    "    feature_vector = model_new.predict(img)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d8c1672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 213ms/step\n",
      "Encoding in Progress Time step 0 \n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Encoding in Progress Time step 1 \n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Encoding in Progress Time step 2 \n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Encoding in Progress Time step 3 \n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "Encoding in Progress Time step 4 \n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Encoding in Progress Time step 5 \n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Encoding in Progress Time step 6 \n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Encoding in Progress Time step 7 \n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Encoding in Progress Time step 8 \n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "Encoding in Progress Time step 9 \n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Encoding in Progress Time step 10 \n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Encoding in Progress Time step 11 \n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Encoding in Progress Time step 12 \n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Encoding in Progress Time step 13 \n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Encoding in Progress Time step 14 \n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "Encoding in Progress Time step 15 \n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Encoding in Progress Time step 16 \n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "Encoding in Progress Time step 17 \n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Encoding in Progress Time step 18 \n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Encoding in Progress Time step 19 \n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Encoding in Progress Time step 20 \n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Encoding in Progress Time step 21 \n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Encoding in Progress Time step 22 \n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Encoding in Progress Time step 23 \n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Encoding in Progress Time step 24 \n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Encoding in Progress Time step 25 \n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Encoding in Progress Time step 26 \n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "Encoding in Progress Time step 27 \n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Encoding in Progress Time step 28 \n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "Encoding in Progress Time step 29 \n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Encoding in Progress Time step 30 \n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Encoding in Progress Time step 31 \n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "Encoding in Progress Time step 32 \n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Encoding in Progress Time step 33 \n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Encoding in Progress Time step 34 \n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Encoding in Progress Time step 35 \n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Encoding in Progress Time step 36 \n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Encoding in Progress Time step 37 \n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "Encoding in Progress Time step 38 \n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Encoding in Progress Time step 39 \n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Encoding in Progress Time step 40 \n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Encoding in Progress Time step 41 \n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Encoding in Progress Time step 42 \n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Encoding in Progress Time step 43 \n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Encoding in Progress Time step 44 \n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Encoding in Progress Time step 45 \n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Encoding in Progress Time step 46 \n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Encoding in Progress Time step 47 \n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "Encoding in Progress Time step 48 \n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Encoding in Progress Time step 49 \n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Encoding in Progress Time step 50 \n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Encoding in Progress Time step 51 \n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Encoding in Progress Time step 52 \n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "Encoding in Progress Time step 53 \n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Encoding in Progress Time step 54 \n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Encoding in Progress Time step 55 \n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Encoding in Progress Time step 56 \n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Encoding in Progress Time step 57 \n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Encoding in Progress Time step 58 \n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Encoding in Progress Time step 59 \n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Encoding in Progress Time step 60 \n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Encoding in Progress Time step 61 \n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Encoding in Progress Time step 62 \n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Encoding in Progress Time step 63 \n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Encoding in Progress Time step 64 \n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "Encoding in Progress Time step 65 \n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Encoding in Progress Time step 66 \n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Encoding in Progress Time step 67 \n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Encoding in Progress Time step 68 \n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Encoding in Progress Time step 69 \n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Encoding in Progress Time step 70 \n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "Encoding in Progress Time step 71 \n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Encoding in Progress Time step 72 \n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Encoding in Progress Time step 73 \n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Encoding in Progress Time step 74 \n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "Encoding in Progress Time step 75 \n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Encoding in Progress Time step 76 \n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Encoding in Progress Time step 77 \n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Encoding in Progress Time step 78 \n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Encoding in Progress Time step 79 \n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Encoding in Progress Time step 80 \n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Encoding in Progress Time step 81 \n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Encoding in Progress Time step 82 \n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Encoding in Progress Time step 83 \n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Encoding in Progress Time step 84 \n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Encoding in Progress Time step 85 \n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Encoding in Progress Time step 86 \n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Encoding in Progress Time step 87 \n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "Encoding in Progress Time step 88 \n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Encoding in Progress Time step 89 \n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Encoding in Progress Time step 90 \n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Encoding in Progress Time step 91 \n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Encoding in Progress Time step 92 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step\n",
      "Encoding in Progress Time step 93 \n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Encoding in Progress Time step 94 \n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Encoding in Progress Time step 95 \n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Encoding in Progress Time step 96 \n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Encoding in Progress Time step 97 \n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Encoding in Progress Time step 98 \n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Encoding in Progress Time step 99 \n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Encoding in Progress Time step 100 \n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Encoding in Progress Time step 101 \n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Encoding in Progress Time step 102 \n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "Encoding in Progress Time step 103 \n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Encoding in Progress Time step 104 \n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Encoding in Progress Time step 105 \n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Encoding in Progress Time step 106 \n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "Encoding in Progress Time step 107 \n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Encoding in Progress Time step 108 \n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Encoding in Progress Time step 109 \n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Encoding in Progress Time step 110 \n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Encoding in Progress Time step 111 \n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Encoding in Progress Time step 112 \n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "Encoding in Progress Time step 113 \n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "Encoding in Progress Time step 114 \n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Encoding in Progress Time step 115 \n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Encoding in Progress Time step 116 \n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "Encoding in Progress Time step 117 \n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Encoding in Progress Time step 118 \n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Encoding in Progress Time step 119 \n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Encoding in Progress Time step 120 \n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "Encoding in Progress Time step 121 \n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "Encoding in Progress Time step 122 \n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Encoding in Progress Time step 123 \n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "Encoding in Progress Time step 124 \n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Encoding in Progress Time step 125 \n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Encoding in Progress Time step 126 \n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "Encoding in Progress Time step 127 \n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Encoding in Progress Time step 128 \n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Encoding in Progress Time step 129 \n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Encoding in Progress Time step 130 \n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Encoding in Progress Time step 131 \n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "Encoding in Progress Time step 132 \n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Encoding in Progress Time step 133 \n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Encoding in Progress Time step 134 \n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Encoding in Progress Time step 135 \n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Encoding in Progress Time step 136 \n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Encoding in Progress Time step 137 \n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Encoding in Progress Time step 138 \n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Encoding in Progress Time step 139 \n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Encoding in Progress Time step 140 \n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Encoding in Progress Time step 141 \n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "Encoding in Progress Time step 142 \n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Encoding in Progress Time step 143 \n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Encoding in Progress Time step 144 \n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Encoding in Progress Time step 145 \n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Encoding in Progress Time step 146 \n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "Encoding in Progress Time step 147 \n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "Encoding in Progress Time step 148 \n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Encoding in Progress Time step 149 \n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Encoding in Progress Time step 150 \n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Encoding in Progress Time step 151 \n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Encoding in Progress Time step 152 \n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Encoding in Progress Time step 153 \n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Encoding in Progress Time step 154 \n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Encoding in Progress Time step 155 \n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Encoding in Progress Time step 156 \n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Encoding in Progress Time step 157 \n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "Encoding in Progress Time step 158 \n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "Encoding in Progress Time step 159 \n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "Encoding in Progress Time step 160 \n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Encoding in Progress Time step 161 \n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Encoding in Progress Time step 162 \n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Encoding in Progress Time step 163 \n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Encoding in Progress Time step 164 \n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Encoding in Progress Time step 165 \n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "Encoding in Progress Time step 166 \n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Encoding in Progress Time step 167 \n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "Encoding in Progress Time step 168 \n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Encoding in Progress Time step 169 \n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Encoding in Progress Time step 170 \n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Encoding in Progress Time step 171 \n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "Encoding in Progress Time step 172 \n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Encoding in Progress Time step 173 \n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "Encoding in Progress Time step 174 \n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Encoding in Progress Time step 175 \n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Encoding in Progress Time step 176 \n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Encoding in Progress Time step 177 \n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "Encoding in Progress Time step 178 \n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Encoding in Progress Time step 179 \n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Encoding in Progress Time step 180 \n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Encoding in Progress Time step 181 \n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "Encoding in Progress Time step 182 \n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "Encoding in Progress Time step 183 \n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "Encoding in Progress Time step 184 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step\n",
      "Encoding in Progress Time step 185 \n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Encoding in Progress Time step 186 \n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Encoding in Progress Time step 187 \n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Encoding in Progress Time step 188 \n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Encoding in Progress Time step 189 \n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Encoding in Progress Time step 190 \n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Encoding in Progress Time step 191 \n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Encoding in Progress Time step 192 \n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Encoding in Progress Time step 193 \n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Encoding in Progress Time step 194 \n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Encoding in Progress Time step 195 \n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Encoding in Progress Time step 196 \n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Encoding in Progress Time step 197 \n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Encoding in Progress Time step 198 \n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Encoding in Progress Time step 199 \n",
      "Total Time Taken : 41.117870807647705\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "encodings =[]\n",
    "\n",
    "for ix,img in enumerate(all_images):\n",
    "#     print(img.shape)\n",
    "    encodings.append(encode_image(img))\n",
    "    print(\"Encoding in Progress Time step %d \"%ix)\n",
    "\n",
    "# encoding_human = model_new.predict(all_images_human)\n",
    "\n",
    "end_time = time()\n",
    "print(\"Total Time Taken :\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00320721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file saved already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33dba91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved/encodings.pkl\",\"wb\") as f:\n",
    "    pickle.dump(encodings,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581124b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac64c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f484fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd5f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a637b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950776e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dad7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c675d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66568319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1c1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b8290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
